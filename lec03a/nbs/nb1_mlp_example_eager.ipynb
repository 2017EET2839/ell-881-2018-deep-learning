{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.tensorflow.org/guide/eager\n",
    "\n",
    "In this noteboook, we would see at a high level how layers are composed\n",
    "\n",
    "**Do not worry** much about the internals such as how data is getting processed for now. \n",
    "We will cover it in more detail later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setting up eager\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Model\n",
    "\n",
    "This Model has three layers: f1, f2 and f3\n",
    "\n",
    "* f1 and f2 are **hidden layers**\n",
    "* f3 is the **output layer**\n",
    "\n",
    "\n",
    "* Keras Dense layer defines the function $y = g(W^T \\boldsymbol{x} + b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Call init of base class\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        #Define the first hidden layer, it outputs 20 units\n",
    "        self.f1 = tf.keras.layers.Dense(units=20, name='f1')\n",
    "        \n",
    "        #Define the second hidden layer, it outputs 100 units\n",
    "        self.f2 = tf.keras.layers.Dense(units=100, name='f2')\n",
    "        \n",
    "        #Define the final layer (output layer), it outputs 10 units\n",
    "        #Though, we want probability, we keep it at logits, as loss function expects logits\n",
    "        self.f3 = tf.keras.layers.Dense(units=10, name='f3')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        result = self.f1(inputs)\n",
    "        result = self.f2(result)\n",
    "        result = self.f3(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "dataset_train = dataset.train('./datasets').shuffle(60000).repeat(4).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs, sample_labels = iter(dataset_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36, shape=(32,), dtype=int32, numpy=\n",
       "array([9, 9, 3, 3, 3, 6, 0, 7, 1, 6, 1, 2, 4, 0, 1, 2, 4, 3, 4, 6, 6, 3,\n",
       "       4, 2, 4, 9, 4, 7, 6, 4, 6, 6], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define **loss** and **gradient** computation. \n",
    "Again, don't worry much about this now. We will cover this in more detail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "  prediction = model(x)\n",
    "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=prediction)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_output = model(sample_inputs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'mlp_model/f1/kernel:0' shape=(784, 20) dtype=float32, numpy=\n",
       "array([[-0.05226948, -0.03380045, -0.08593247, ...,  0.04665427,\n",
       "         0.07489154, -0.08402053],\n",
       "       [-0.00887366, -0.04801061,  0.04629155, ...,  0.07592633,\n",
       "         0.04981589, -0.02024387],\n",
       "       [-0.06243209,  0.01732839, -0.03583066, ...,  0.04256839,\n",
       "         0.01026747, -0.06153925],\n",
       "       ...,\n",
       "       [-0.07873483, -0.07596295,  0.04450297, ...,  0.03286304,\n",
       "        -0.07224698, -0.05948465],\n",
       "       [-0.08518442, -0.04949057, -0.03061088, ..., -0.06696609,\n",
       "        -0.05911696,  0.00808229],\n",
       "       [-0.00111673,  0.00836813, -0.04163161, ..., -0.03101798,\n",
       "         0.0459934 , -0.0301648 ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0000: 2.487\n",
      "Loss at step 0200: 2.256\n",
      "Loss at step 0400: 1.944\n",
      "Loss at step 0600: 1.825\n",
      "Loss at step 0800: 1.947\n",
      "Loss at step 1000: 1.655\n",
      "Loss at step 1200: 1.523\n",
      "Loss at step 1400: 1.227\n",
      "Loss at step 1600: 1.267\n",
      "Loss at step 1800: 1.090\n",
      "Loss at step 2000: 1.132\n",
      "Loss at step 2200: 1.079\n",
      "Loss at step 2400: 1.023\n",
      "Loss at step 2600: 0.699\n",
      "Loss at step 2800: 0.817\n",
      "Loss at step 3000: 0.838\n",
      "Loss at step 3200: 0.850\n",
      "Loss at step 3400: 0.669\n",
      "Loss at step 3600: 0.744\n",
      "Loss at step 3800: 0.613\n",
      "Loss at step 4000: 0.661\n",
      "Loss at step 4200: 0.645\n",
      "Loss at step 4400: 0.457\n",
      "Loss at step 4600: 0.667\n",
      "Loss at step 4800: 0.643\n",
      "Loss at step 5000: 0.571\n",
      "Loss at step 5200: 0.531\n",
      "Loss at step 5400: 0.609\n",
      "Loss at step 5600: 0.853\n",
      "Loss at step 5800: 0.645\n",
      "Loss at step 6000: 0.682\n",
      "Loss at step 6200: 0.659\n",
      "Loss at step 6400: 0.713\n",
      "Loss at step 6600: 0.411\n",
      "Loss at step 6800: 0.333\n",
      "Loss at step 7000: 0.841\n",
      "Loss at step 7200: 0.353\n",
      "Loss at step 7400: 0.461\n",
      "Final loss: 0.701\n"
     ]
    }
   ],
   "source": [
    "for (i, (x, y)) in enumerate(dataset_train):\n",
    "  # Calculate derivatives of the input function with respect to its parameters.\n",
    "  grads = grad(model, x, y)\n",
    "  # Apply the gradient to the model\n",
    "  optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                            global_step=tf.train.get_or_create_global_step())\n",
    "  if i % 200 == 0:\n",
    "    print(\"Loss at step {:04d}: {:.3f}\".format(i, loss(model, x, y)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model, x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=669252, shape=(32, 20), dtype=float32, numpy=\n",
       "array([[ 2.18208611e-01,  4.28503871e-01,  4.53877926e-01,\n",
       "         2.94955564e+00,  2.19059587e+00,  4.45727021e-01,\n",
       "         1.06557643e+00,  2.18106091e-01, -8.03283677e-02,\n",
       "         2.56836265e-01,  1.60441983e+00,  6.09335124e-01,\n",
       "        -7.75609672e-01,  8.64541292e-01,  1.10543418e+00,\n",
       "        -3.99508566e-01, -5.24423242e-01,  8.73880208e-01,\n",
       "        -4.72689047e-02, -1.09459773e-01],\n",
       "       [-7.80479684e-02,  6.24355614e-01,  1.16547632e+00,\n",
       "         3.12190580e+00,  1.31616664e+00,  4.43734348e-01,\n",
       "         7.20943213e-01,  2.35968903e-01, -1.38449764e+00,\n",
       "         2.38115400e-01,  1.51751077e+00,  8.83800805e-01,\n",
       "        -3.04454193e-02,  9.83679414e-01,  4.82652068e-01,\n",
       "         1.25105828e-01, -6.61685467e-01, -2.43675057e-02,\n",
       "        -1.32365793e-01, -2.10726097e-01],\n",
       "       [-2.24857569e+00,  5.82521617e-01,  1.15649486e+00,\n",
       "        -1.20614827e+00,  5.86040735e-01,  7.23572731e-01,\n",
       "        -1.63251948e+00, -9.23027992e-01, -2.57565284e+00,\n",
       "         5.02468683e-02, -5.98531179e-02,  2.67728806e+00,\n",
       "        -2.92788967e-02,  1.06142890e+00,  1.98129606e+00,\n",
       "        -6.00343585e-01,  1.01252127e+00,  1.29413319e+00,\n",
       "        -1.07103646e+00,  5.59241176e-01],\n",
       "       [-1.68277776e+00,  5.71483195e-01,  6.68846130e-01,\n",
       "        -3.28407288e-01,  1.06658721e+00,  6.69143558e-01,\n",
       "         1.07827231e-01, -2.47760862e-01, -2.62430501e+00,\n",
       "        -5.58927238e-01,  2.76972115e-01,  3.00342727e+00,\n",
       "        -9.04193759e-01,  3.36052060e-01,  3.20680439e-01,\n",
       "        -9.63550329e-01,  1.54775310e+00,  5.52551448e-01,\n",
       "        -4.11241889e-01,  8.21138144e-01],\n",
       "       [-2.24959016e+00,  7.57012308e-01,  1.52503884e+00,\n",
       "        -2.16724753e+00, -2.33445138e-01,  5.73996842e-01,\n",
       "        -3.08858216e-01, -8.16602945e-01, -1.27696562e+00,\n",
       "         4.43189353e-01, -8.59309554e-01,  1.93744886e+00,\n",
       "         1.92825705e-01, -1.22083709e-01,  1.87786102e+00,\n",
       "        -8.27881455e-01,  1.43579853e+00,  1.11953008e+00,\n",
       "        -7.93415666e-01,  4.21427608e-01],\n",
       "       [-3.71871710e-01,  8.34841505e-02,  2.73975682e+00,\n",
       "        -1.11365187e+00,  1.04971623e+00,  9.78798211e-01,\n",
       "         3.24479759e-01, -9.63965710e-03,  7.28764609e-02,\n",
       "         1.53720796e+00,  3.76372933e-01,  6.78694248e-02,\n",
       "         2.19175434e+00,  1.46572065e+00,  2.26139092e+00,\n",
       "         3.45133990e-01, -3.99452716e-01,  3.23914170e-01,\n",
       "        -1.51793492e+00,  9.04038191e-01],\n",
       "       [-4.27524596e-01, -9.73694623e-01,  2.01809621e+00,\n",
       "         5.89992814e-02,  1.27873623e+00, -1.02555573e+00,\n",
       "        -1.66575992e+00, -1.58395302e+00, -8.75867069e-01,\n",
       "        -1.37195587e+00,  5.66866219e-01,  1.02344418e+00,\n",
       "         1.16125858e+00, -7.42882311e-01,  3.76314664e+00,\n",
       "         8.51328611e-01, -1.34759867e+00,  2.28294039e+00,\n",
       "        -5.60817361e-01, -2.21908379e+00],\n",
       "       [ 6.80395246e-01, -1.14937758e+00,  4.41483140e-01,\n",
       "         1.68307185e+00,  2.39691162e+00,  1.41587943e-01,\n",
       "        -6.66829586e-01, -3.73929143e-01,  4.69868988e-01,\n",
       "        -7.81109750e-01,  7.82357812e-01, -6.12651259e-02,\n",
       "        -3.45219880e-01, -3.96163106e-01,  1.72963703e+00,\n",
       "        -8.21655631e-01, -8.76753330e-01,  1.77958047e+00,\n",
       "         1.48034975e-01, -1.49928427e+00],\n",
       "       [-2.02874929e-01,  1.71863961e+00, -1.91873550e-01,\n",
       "        -1.82357264e+00, -1.06942511e+00,  3.45962852e-01,\n",
       "         1.92275524e+00,  2.31193721e-01, -7.90340960e-01,\n",
       "         1.09769487e+00, -2.85089552e-01,  7.97744393e-01,\n",
       "         3.58336955e-01, -3.37886751e-01, -4.54571664e-01,\n",
       "        -4.87287492e-01,  3.62893492e-01, -1.15342355e+00,\n",
       "        -6.61692619e-01,  9.63674307e-01],\n",
       "       [ 6.59569561e-01, -7.53814995e-01,  2.14667988e+00,\n",
       "         2.12276816e+00,  7.99075484e-01, -1.32799357e-01,\n",
       "         4.53696549e-01, -3.59726250e-02,  1.02003443e+00,\n",
       "         1.70491099e-01,  8.40440452e-01, -9.73718107e-01,\n",
       "         1.47719145e+00,  8.40669274e-01,  5.48460543e-01,\n",
       "         1.23446953e+00, -4.15888876e-01, -5.36213577e-01,\n",
       "        -1.48556149e+00,  8.84608328e-01],\n",
       "       [ 2.42099136e-01,  1.45113659e+00, -7.12148666e-01,\n",
       "        -9.17597651e-01, -6.82690084e-01,  2.68676728e-01,\n",
       "         1.15456891e+00,  2.06169665e-01, -6.18380845e-01,\n",
       "         6.26055598e-01,  1.58555403e-01,  2.12399423e-01,\n",
       "        -7.94751570e-02, -5.80185175e-01, -8.10490906e-01,\n",
       "        -9.09768105e-01,  1.23166159e-01, -4.76215214e-01,\n",
       "        -1.17891207e-01,  2.69225597e-01],\n",
       "       [-8.53549063e-01,  8.55497301e-01,  1.08815217e+00,\n",
       "         3.21249276e-01, -2.00232670e-01, -7.39938259e-01,\n",
       "         2.26689383e-01, -1.97920412e-01, -1.76845253e+00,\n",
       "        -3.56241554e-01,  3.92949402e-01,  1.28136671e+00,\n",
       "         6.47308707e-01,  2.89347380e-01, -4.44395155e-01,\n",
       "         3.23521763e-01,  1.67299485e+00, -4.55915302e-01,\n",
       "         2.10390419e-01,  1.35797465e+00],\n",
       "       [-5.20728707e-01, -1.06135941e+00,  1.14680648e+00,\n",
       "         2.12235093e+00,  1.79957414e+00,  1.46180058e+00,\n",
       "         2.72136927e-01, -1.91488698e-01, -1.16158210e-01,\n",
       "         4.11430933e-02,  1.11310399e+00,  1.18429184e+00,\n",
       "        -7.42054805e-02,  1.14959884e+00,  1.87643397e+00,\n",
       "         9.85769391e-01, -1.66663975e-01,  1.58192050e+00,\n",
       "        -5.21111071e-01,  2.13520214e-01],\n",
       "       [-2.30426013e-01, -6.25335276e-01,  2.15101051e+00,\n",
       "         4.61919010e-01,  1.01628530e+00, -4.43000168e-01,\n",
       "        -2.67067075e-01, -1.16246544e-01,  6.40364110e-01,\n",
       "        -5.36213480e-02,  5.79460979e-01, -1.20200604e-01,\n",
       "         1.16536057e+00,  5.90344012e-01,  2.10946178e+00,\n",
       "         8.55480909e-01, -8.35704803e-01,  1.07382333e+00,\n",
       "        -1.49179757e-01, -3.79397631e-01],\n",
       "       [ 2.35582203e-01,  1.07591724e+00, -1.78306550e-01,\n",
       "        -7.23627627e-01, -1.19397378e+00,  2.53675610e-01,\n",
       "         1.29680836e+00, -6.25129864e-02, -9.14197505e-01,\n",
       "         5.76218843e-01, -3.77179116e-01,  2.67034441e-01,\n",
       "        -3.83883953e-01, -5.93314171e-01, -1.05230463e+00,\n",
       "        -5.20975292e-01,  8.05183768e-01, -7.11584628e-01,\n",
       "        -2.71281511e-01,  3.14157873e-01],\n",
       "       [-1.51475179e+00,  3.07475954e-01,  3.57932329e+00,\n",
       "        -1.55861712e+00, -1.27635622e+00,  8.38007778e-02,\n",
       "        -4.62954104e-01, -1.09324419e+00,  7.08782315e-01,\n",
       "         6.04102947e-02,  6.03180707e-01,  6.06214821e-01,\n",
       "         2.85114574e+00,  1.19486880e+00,  2.38883758e+00,\n",
       "         1.42601931e+00,  1.71542263e+00,  7.82472193e-01,\n",
       "        -1.08031595e+00, -3.46427113e-02],\n",
       "       [ 1.59984350e-01, -1.67818204e-01,  1.10250306e+00,\n",
       "         2.38042045e+00,  1.25609696e+00,  7.18687952e-01,\n",
       "         1.28420383e-01,  2.30315015e-01, -6.55744612e-01,\n",
       "         1.81477204e-01,  8.53386343e-01,  5.29182076e-01,\n",
       "         6.73428550e-02,  1.20747173e+00,  6.90803647e-01,\n",
       "         1.94624573e-01,  3.31481993e-02,  5.08470297e-01,\n",
       "        -4.02815968e-01, -6.08611643e-01],\n",
       "       [-2.42887497e-01,  1.11850190e+00,  5.97734571e-01,\n",
       "         1.64122498e+00,  1.43818402e+00, -4.83896047e-01,\n",
       "         2.01533127e+00, -1.04845934e-01, -2.64560246e+00,\n",
       "        -9.74018097e-01,  1.39250147e+00,  2.06787968e+00,\n",
       "        -6.70577943e-01, -5.25217950e-01, -1.77882202e-02,\n",
       "        -8.39720368e-02, -4.14918989e-01, -9.78014395e-02,\n",
       "        -4.05201137e-01,  3.32751751e-01],\n",
       "       [-1.24428666e+00, -3.92716765e-01,  1.78289664e+00,\n",
       "         3.11838818e+00,  5.21327317e-01, -7.63693452e-02,\n",
       "         5.14392316e-01,  2.21486837e-01, -2.62709498e-01,\n",
       "        -9.50804532e-01, -4.13588695e-02, -3.39561850e-02,\n",
       "         2.38015562e-01,  1.67655909e+00, -1.28365591e-01,\n",
       "         1.86498213e+00,  2.29651034e-02,  6.25177398e-02,\n",
       "        -2.31795982e-01, -6.31412566e-01],\n",
       "       [-2.93588609e-01,  2.61404365e-01,  2.76230693e+00,\n",
       "         1.00229287e+00,  2.17305690e-01, -6.94122970e-01,\n",
       "         2.97554910e-01, -4.29679364e-01,  8.21047306e-01,\n",
       "         1.07808575e-01,  1.31386697e+00, -4.91017997e-01,\n",
       "         2.58025336e+00,  1.28765428e+00,  1.37756956e+00,\n",
       "         1.27555740e+00,  1.26759756e+00, -2.55206317e-01,\n",
       "        -1.45835519e-01,  1.98616862e+00],\n",
       "       [-4.67176348e-01,  1.44636050e-01,  1.45903146e+00,\n",
       "        -1.28643763e+00,  8.04230571e-01,  2.74485081e-01,\n",
       "        -3.43020737e-01,  1.70173913e-01, -2.94729829e-01,\n",
       "         1.01244795e+00, -1.37930900e-01,  1.72551110e-01,\n",
       "         7.93170214e-01,  9.64255452e-01,  1.49720526e+00,\n",
       "        -2.69774109e-01, -1.84806615e-01,  3.18996400e-01,\n",
       "        -4.39904571e-01,  4.69932139e-01],\n",
       "       [-8.99192274e-01,  8.10860276e-01,  3.06231260e-01,\n",
       "        -7.48364508e-01, -2.62623996e-01, -2.06788480e-01,\n",
       "        -1.28196526e+00, -1.81698382e+00, -2.19506168e+00,\n",
       "        -3.36835444e-01,  2.46701702e-01,  2.58014822e+00,\n",
       "        -1.40715599e+00, -7.84638584e-01,  1.16827953e+00,\n",
       "        -1.78772330e+00,  6.79209709e-01,  1.39314282e+00,\n",
       "        -2.79539339e-02,  3.30671519e-01],\n",
       "       [-3.86676788e-01,  5.57866633e-01,  1.25146461e+00,\n",
       "         7.79682934e-01,  9.54057813e-01,  1.85887486e-01,\n",
       "         7.86986709e-01,  5.46738803e-01, -5.72316468e-01,\n",
       "         4.24447685e-01,  5.69020748e-01,  3.56377929e-01,\n",
       "         2.41988569e-01,  9.25905049e-01,  7.75299221e-02,\n",
       "        -2.06280917e-01,  6.37546480e-02,  2.91132927e-01,\n",
       "        -7.60090947e-01,  5.94590545e-01],\n",
       "       [-1.94889057e+00,  1.23009825e+00,  2.23532534e+00,\n",
       "        -2.13213071e-01, -8.67622197e-01, -2.54104209e+00,\n",
       "        -1.14525938e+00, -1.48215234e+00, -1.89561033e+00,\n",
       "        -2.53522062e+00,  7.55415380e-01,  2.99600887e+00,\n",
       "         7.41593659e-01, -1.06718433e+00,  9.77407992e-01,\n",
       "        -4.82516587e-02,  1.63332319e+00,  1.06165457e+00,\n",
       "         2.60279268e-01, -5.00025392e-01],\n",
       "       [ 3.54413241e-01, -4.48393673e-01,  1.29041624e+00,\n",
       "         3.27706003e+00,  1.88097811e+00,  1.46217585e+00,\n",
       "         7.36509800e-01,  9.34226736e-02, -1.22210290e-02,\n",
       "         9.86515522e-01,  1.26116049e+00,  6.54202342e-01,\n",
       "        -8.42480883e-02,  1.64586985e+00,  7.45554447e-01,\n",
       "         4.38047498e-01,  6.95326924e-01,  5.10365486e-01,\n",
       "        -4.65109438e-01,  6.70595706e-01],\n",
       "       [ 1.13208222e+00,  5.95833123e-01,  1.33099103e+00,\n",
       "         3.89941931e+00,  2.01679754e+00,  2.78066427e-01,\n",
       "         7.01510012e-01,  1.74643040e-01, -8.80799830e-01,\n",
       "         3.57147545e-01,  2.02290034e+00,  1.07355869e+00,\n",
       "         1.11545540e-01,  9.83687520e-01,  1.15270063e-01,\n",
       "         1.94530517e-01, -1.10141718e+00,  5.53269163e-02,\n",
       "        -5.69067240e-01,  3.09082270e-01],\n",
       "       [-8.07334661e-01, -1.47737527e+00,  3.64135838e+00,\n",
       "         2.56586838e+00,  7.61371911e-01, -1.37431061e+00,\n",
       "         7.04035521e-01, -7.20526755e-01,  1.83051455e+00,\n",
       "        -1.48467541e+00,  4.18910533e-01, -1.02455628e+00,\n",
       "         2.93226385e+00,  1.28970563e+00,  1.42007518e+00,\n",
       "         2.56917262e+00,  4.08885151e-01,  8.61558616e-01,\n",
       "        -6.33492708e-01, -7.21684694e-01],\n",
       "       [ 9.93198276e-01,  1.05568357e-01, -1.22805081e-01,\n",
       "         3.03338456e+00,  2.43729663e+00, -6.68229997e-01,\n",
       "        -2.89415658e-01,  1.55744493e-01, -3.99345875e-01,\n",
       "        -4.83905584e-01,  1.25400758e+00, -1.60572883e-02,\n",
       "        -8.07510257e-01, -6.35554373e-01,  4.19359356e-01,\n",
       "        -1.31861413e+00, -1.78506327e+00,  1.19730270e+00,\n",
       "         2.87085265e-01, -1.52938569e+00],\n",
       "       [-7.90296718e-02,  1.57184768e+00,  2.01699567e+00,\n",
       "        -4.73217219e-01, -2.16651652e-02,  9.34967622e-02,\n",
       "         2.39334989e+00,  6.37638152e-01,  6.13010347e-01,\n",
       "         1.70657396e+00,  1.13672411e+00, -1.17466956e-01,\n",
       "         1.27989197e+00,  1.13878930e+00,  7.34188199e-01,\n",
       "         3.22597921e-02,  2.12494105e-01, -1.06050873e+00,\n",
       "        -1.45315516e+00,  1.89115822e+00],\n",
       "       [ 2.95233935e-01,  4.71995175e-01,  7.86752343e-01,\n",
       "         2.08151960e+00,  1.48967707e+00,  3.09926987e-01,\n",
       "         9.30613220e-01, -1.30260855e-01, -5.30956328e-01,\n",
       "         2.04874426e-01,  1.37153614e+00,  8.98793638e-01,\n",
       "        -4.83827025e-01,  4.46075827e-01,  3.08093429e-01,\n",
       "         1.57624364e-01,  9.97957230e-01,  4.46430594e-01,\n",
       "        -2.53502935e-01,  1.08909523e+00],\n",
       "       [-1.24135770e-01, -1.49967283e-01,  1.75829887e+00,\n",
       "         1.39944327e+00,  4.08401132e-01, -1.06117260e+00,\n",
       "         1.11879647e+00,  1.73057944e-01,  4.35525253e-02,\n",
       "        -6.58033013e-01,  5.94202280e-01, -2.31102943e-01,\n",
       "         9.06248868e-01, -3.60215968e-03, -3.42167825e-01,\n",
       "         6.05102658e-01,  1.28001547e+00, -1.03106236e+00,\n",
       "        -2.70492405e-01, -1.01421610e-01],\n",
       "       [-7.61999264e-02,  5.04123151e-01,  2.70655060e+00,\n",
       "         8.10261890e-02, -1.11186780e-01, -3.06225002e-01,\n",
       "         1.04161787e+00, -1.35879144e-01,  5.91294587e-01,\n",
       "        -1.08336002e-01,  6.20087028e-01, -3.03869933e-01,\n",
       "         2.08341932e+00,  1.09826529e+00,  2.20633340e+00,\n",
       "         1.84916902e+00,  5.24662375e-01,  4.77272391e-01,\n",
       "        -3.65387619e-01,  8.25729847e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.f1(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
