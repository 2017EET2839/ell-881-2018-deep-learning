{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#This should be the first statement when running tf.eager\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary for reproducibility!\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input data and ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(dtype=np.float32, a=[[0,0], [1,0], [0,1], [1,1]])\n",
    "Y = np.expand_dims(np.asarray(dtype=np.float32, a=[0., 1., 1., 0.]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearXORModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearXORModel, self).__init__()\n",
    "        #Let us add a *linear* hidden layer\n",
    "        self.f1 = tf.keras.layers.Dense(units=2, kernel_initializer='random_normal')\n",
    "        self.f2 = tf.keras.layers.Dense(units=1, kernel_initializer='random_normal')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h = self.f1(inputs)\n",
    "        return self.f2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearXORModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=52, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.       ],\n",
       "       [0.7530006],\n",
       "       [1.238671 ],\n",
       "       [1.9916714]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.convert_to_tensor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, X, Y):\n",
    "  predictions = model(X)\n",
    "  return tf.losses.mean_squared_error(labels=tf.convert_to_tensor(Y), predictions=predictions)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0000: 1.003\n",
      "Loss at step 1000: 0.276\n",
      "Loss at step 2000: 0.254\n",
      "Loss at step 3000: 0.251\n",
      "Loss at step 4000: 0.250\n",
      "Loss at step 5000: 0.250\n",
      "Loss at step 6000: 0.250\n",
      "Loss at step 7000: 0.250\n",
      "Loss at step 8000: 0.250\n",
      "Loss at step 9000: 0.250\n",
      "Final loss: 0.250\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "  # Calculate derivatives of the input function with respect to its parameters.\n",
    "  grads = grad(model, X, Y)\n",
    "  # Apply the gradient to the model\n",
    "  optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\n",
    "  if step % 1000 == 0:\n",
    "    print(\"Loss at step {:04d}: {:.3f}\".format(step, loss(model, X, Y)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model, X, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model **still fails** to learn, all points output 0.5!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=880486, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.50173515],\n",
       "       [0.49133766],\n",
       "       [0.5086126 ],\n",
       "       [0.4982151 ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
