{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#This should be the first statement when running tf.eager\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary for reproducibility!\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input data and ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(dtype=np.float32, a=[[0,0], [1,0], [0,1], [1,1]])\n",
    "Y = np.expand_dims(np.asarray(dtype=np.float32, a=[0., 1., 1., 0.]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearXORModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearXORModel, self).__init__()\n",
    "        #Let us add a *linear* hidden layer\n",
    "        self.f1 = tf.keras.layers.Dense(units=2, kernel_initializer='random_normal', activation='relu', bias_initializer='uniform')\n",
    "        self.f2 = tf.keras.layers.Dense(units=1, kernel_initializer='random_normal')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h = self.f1(inputs)\n",
    "        return self.f2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearXORModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=57, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[-0.64365935],\n",
       "       [-0.56768495],\n",
       "       [-0.5631927 ],\n",
       "       [-0.7462795 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.convert_to_tensor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, X, Y):\n",
    "  predictions = model(X)\n",
    "  return tf.losses.mean_squared_error(labels=tf.convert_to_tensor(Y), predictions=predictions)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0000: 1.442\n",
      "Loss at step 1000: 0.181\n",
      "Loss at step 2000: 0.164\n",
      "Loss at step 3000: 0.151\n",
      "Loss at step 4000: 0.139\n",
      "Loss at step 5000: 0.123\n",
      "Loss at step 6000: 0.105\n",
      "Loss at step 7000: 0.086\n",
      "Loss at step 8000: 0.067\n",
      "Loss at step 9000: 0.051\n",
      "Loss at step 10000: 0.037\n",
      "Loss at step 11000: 0.025\n",
      "Loss at step 12000: 0.017\n",
      "Loss at step 13000: 0.010\n",
      "Loss at step 14000: 0.005\n",
      "Loss at step 15000: 0.003\n",
      "Loss at step 16000: 0.001\n",
      "Loss at step 17000: 0.001\n",
      "Loss at step 18000: 0.000\n",
      "Loss at step 19000: 0.000\n",
      "Final loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for step in range(20000):\n",
    "  # Calculate derivatives of the input function with respect to its parameters.\n",
    "  grads = grad(model, X, Y)\n",
    "  # Apply the gradient to the model\n",
    "  optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\n",
    "  if step % 1000 == 0:\n",
    "    print(\"Loss at step {:04d}: {:.3f}\".format(step, loss(model, X, Y)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model, X, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1800882, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.00144255],\n",
       "       [0.9935096 ],\n",
       "       [0.99350923],\n",
       "       [0.00854647]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hidden representations learn to map input to linearly separable points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        1.1912402]\n",
      " [0.6890116 0.       ]\n",
      " [0.6890119 0.       ]\n",
      " [1.5744605 0.       ]]\n"
     ]
    }
   ],
   "source": [
    "h = model.f1(X).numpy()\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x129068dd8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(h[:,0], h[:,1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
